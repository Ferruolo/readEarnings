{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas\n",
    "import numpy\n",
    "#Important note: This notebook is not optimized for speed, rather it is meant to be readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"not-pdf.txt\", \"r\", encoding='cp1252') as f:\n",
    "    transcripts = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First lets get the data we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_dots = transcripts.split(\"...\")\n",
    "not_empty = ''\n",
    "for string in split_by_dots:\n",
    "    if string != '':\n",
    "        not_empty += string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_call = not_empty.split(\"Corrected Transcript\")[1:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now time to preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "vecs = tf_idf.fit_transform(split_by_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tf_idf.inverse_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to w2v\n",
    "import gensim\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"w2vfile\", binary=True)\n",
    "vectors = list()\n",
    "for call in tokens:\n",
    "    w2v_call = list()\n",
    "    for word in call:\n",
    "#         if not(word in zero_words):\n",
    "#             print(\"Its not the condition\")\n",
    "        try:\n",
    "#             print(word)\n",
    "            w2v_call.append(w2v[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    vectors.append(w2v_call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_data = numpy.array([\n",
    "    -45.2,\n",
    "    0.8,\n",
    "    6.0,\n",
    "    39.3,\n",
    "    753.6,\n",
    "    26.9,\n",
    "    5.1,\n",
    "    3030.7,\n",
    "    31, \n",
    "    62.9,\n",
    "    22.4,\n",
    "    12.0,\n",
    "    4.6,\n",
    "    -2.2,\n",
    "    15.5,\n",
    "    4.0,\n",
    "    -2,\n",
    "    4.6,\n",
    "    0.2,\n",
    "    10.5,\n",
    "    15.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_data = earnings_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_earnings_data = normalize(earnings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = list()\n",
    "for i in range(3, len(vectors)):\n",
    "    calls = [vectors[call] for call in range(i-3, i)]\n",
    "    returns = norm_earnings_data[i-3]\n",
    "    grouped_data.append([calls, returns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle = {\n",
    "    'DATA':grouped_data,\n",
    "    'TRANSCRIPTS_W2V':vectors,\n",
    "    'Earnings': norm_earnings_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(to_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
